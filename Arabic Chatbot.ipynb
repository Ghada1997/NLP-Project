{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathy-Driven Arabic Chatbot\n",
    "\n",
    "\n",
    "\n",
    "### Team\n",
    "\n",
    "#### Member 1: Noor Elkindy (31-9103)\n",
    "\n",
    "#### Member 2: Ghada Mansour (40-9240)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from nltk.stem.isri import ISRIStemmer #ISRIStemmer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#nltk.download('all')\n",
    "#pip install torch torchvision==0.10.0 torchaudio===0.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cleaning and Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>أجل؟ أنا حقا لا أرى كيف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>لا تشعر بذلك .. إنه لأمر عجيب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>أصطدم بالفعل بجدران فارغة في كثير من الأحيان ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>ظننت ذلك عمليا .. وكنت أتعرق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>afraid</td>\n",
       "      <td>كنت أخاف من الظلام</td>\n",
       "      <td>انتظر ما هو العرق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>afraid</td>\n",
       "      <td>في العام الماضي ، سقطت شجرة على منزلي بينما كا...</td>\n",
       "      <td>ما الفرق الذي يحدثه العام. في إحدى الأمسيات من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>afraid</td>\n",
       "      <td>في العام الماضي ، سقطت شجرة على منزلي بينما كا...</td>\n",
       "      <td>هذا مخيف جدا. آمل ألا يصاب أحد بأذى.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>afraid</td>\n",
       "      <td>في العام الماضي ، سقطت شجرة على منزلي بينما كا...</td>\n",
       "      <td>كنا على ما يرام ، على الرغم من أن الشجرة اخترق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>afraid</td>\n",
       "      <td>في العام الماضي ، سقطت شجرة على منزلي بينما كا...</td>\n",
       "      <td>سعداء جدا الجميع بخير !! يمكن إصلاح كل شيء آخر.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   utterance_idx context                                             prompt  \\\n",
       "0              1  afraid                                 كنت أخاف من الظلام   \n",
       "1              2  afraid                                 كنت أخاف من الظلام   \n",
       "2              3  afraid                                 كنت أخاف من الظلام   \n",
       "3              4  afraid                                 كنت أخاف من الظلام   \n",
       "4              5  afraid                                 كنت أخاف من الظلام   \n",
       "5              6  afraid                                 كنت أخاف من الظلام   \n",
       "6              1  afraid  في العام الماضي ، سقطت شجرة على منزلي بينما كا...   \n",
       "7              2  afraid  في العام الماضي ، سقطت شجرة على منزلي بينما كا...   \n",
       "8              3  afraid  في العام الماضي ، سقطت شجرة على منزلي بينما كا...   \n",
       "9              4  afraid  في العام الماضي ، سقطت شجرة على منزلي بينما كا...   \n",
       "\n",
       "                                           utterance  \n",
       "0     أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام  \n",
       "1                            أجل؟ أنا حقا لا أرى كيف  \n",
       "2                      لا تشعر بذلك .. إنه لأمر عجيب  \n",
       "3  أصطدم بالفعل بجدران فارغة في كثير من الأحيان ل...  \n",
       "4                       ظننت ذلك عمليا .. وكنت أتعرق  \n",
       "5                                  انتظر ما هو العرق  \n",
       "6  ما الفرق الذي يحدثه العام. في إحدى الأمسيات من...  \n",
       "7               هذا مخيف جدا. آمل ألا يصاب أحد بأذى.  \n",
       "8  كنا على ما يرام ، على الرغم من أن الشجرة اخترق...  \n",
       "9    سعداء جدا الجميع بخير !! يمكن إصلاح كل شيء آخر.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Dataset\n",
    "df = pd.read_csv('arabic dataset train_2.csv'  , encoding = 'utf-16',low_memory=False)\n",
    "\n",
    "# Dropping unwanted Columns\n",
    "df = df.drop(df.loc[:,'selfeval':], axis=1) \n",
    "df = df.drop(['conv_id','speaker_idx','prompt','utterance'], axis=1)\n",
    "\n",
    "# Renaming Columns\n",
    "df = df.rename(columns={'translated_prompt':'prompt','translated_utterance':'utterance' })\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utterance_idx    0\n",
       "context          0\n",
       "prompt           0\n",
       "utterance        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure it doesn't have any Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5323 entries, 0 to 5322\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   utterance_idx  5323 non-null   int64 \n",
      " 1   context        5323 non-null   object\n",
      " 2   prompt         5323 non-null   object\n",
      " 3   utterance      5323 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 166.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5323, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions\n",
    "\n",
    "Here removing Punctuations is done before Tokenization since Punctuations in Arabic are not part of the words, unlike English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuations, Numbers and English Words\n",
    "\n",
    "def ignore_words(sent):\n",
    "    \n",
    "    arabic_punctuations = [\"؛\",\".\",\"،\",\",\",\"!\",\"؟\",\"×\",\"÷\",\"*\",\"%\",\"&\",\"#\",\"?\",\"$\",\"٪\",\"`\",\"'\",'\"',\"ً\"] #Tanween (Nunation) was handled between the last Quotations, however it is not obvious  \n",
    "    new_sent = ''\n",
    "    \n",
    "    sent = re.sub(r'[0-9a-zA-Z]', '', sent)\n",
    "    \n",
    "    for w in sent:\n",
    "        if w not in arabic_punctuations:\n",
    "            new_sent += w\n",
    "    \n",
    "    return new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "isri = ISRIStemmer()\n",
    "\n",
    "def stem(word):\n",
    "    return isri.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the needed Preprocessing\n",
    "\n",
    "def preprocessing(sent):\n",
    "    sent = ignore_words(sent)\n",
    "    sent = tokenize(sent)\n",
    "    sent = [stem(word) for word in sent]\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words\n",
    "\n",
    "def bag_of_words(preprocessed_sentence, all_words):\n",
    "    bag = np.zeros(len(all_words), dtype = np.float32)\n",
    "    \n",
    "    for idx, word in enumerate(all_words):\n",
    "        if word in preprocessed_sentence: \n",
    "            bag[idx] = 1.0\n",
    "            \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2772, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the Input Texts only for each Conversation in the Utterance based on the Utterance ID\n",
    "\n",
    "df_cntxt_input_utt = df.copy()\n",
    "df_cntxt_input_utt.shape\n",
    "\n",
    "for index, row in df_cntxt_input_utt.iterrows():\n",
    "    if (row['utterance_idx'] % 2 == 0):\n",
    "        df_cntxt_input_utt = df_cntxt_input_utt.drop(index) \n",
    "        \n",
    "df_cntxt_input_utt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cntxt_input_utt= df_cntxt_input_utt.drop(['utterance_idx','prompt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the needed Variables for the Model\n",
    "\n",
    "all_words = []\n",
    "contexts = []\n",
    "xy = []\n",
    "\n",
    "\n",
    "for index, item in df_cntxt_input_utt.iterrows():\n",
    "    context = item['context']\n",
    "    contexts.append(context)\n",
    "    utterance = preprocessing(item['utterance'])\n",
    "    all_words.extend(utterance)\n",
    "    xy.append((utterance, context))\n",
    "\n",
    "all_words = sorted(set(all_words)) #sorting and removing duplicates \n",
    "contexts = sorted(set(contexts)) #sorting and removing duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Training Dataset\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for (utterance, context) in xy:\n",
    "    bag = bag_of_words(utterance, all_words)\n",
    "    x_train.append(bag)\n",
    "    \n",
    "    label = contexts.index(context)\n",
    "    y_train.append(label)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train, dtype = np.longlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom Dataset\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(x_train)\n",
    "        self.x_data = x_train\n",
    "        self.y_data = y_train\n",
    "        \n",
    "    # allowing indexing the Dataset\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    # len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0338\n",
      "Epoch [200/1000], Loss: 0.0398\n",
      "Epoch [300/1000], Loss: 0.0001\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "final loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Applying the Training Model on the Dataset\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "batch_size = 32  #This Batch Size is chosen since it is the standard one (best one for small Datasets)\n",
    "input_size = len(x_train[0]) #length of each bag_of_words, which is equals to length of all_words array\n",
    "hidden_size = 32  #it is suggested to be a Value between the input_size and output_size. After Testing, 32 was the best Value\n",
    "output_size = len(contexts)  #Number of different classes we have in the Contexts\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.007 #After testing different Learning Rates, 0.007 was the best one in Training the Model\n",
    "\n",
    "dataset = ChatbotDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for words, labels in train_loader: #Batch Data\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(words)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass and optimzation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving Data\n",
    "\n",
    "data = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"all_words\": all_words,\n",
    "    \"contexts\": contexts\n",
    "}\n",
    "\n",
    "FILE = 'data.pth'\n",
    "torch.save(data, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(اكتب \"إغلاق\" لإنهاء المحادثة)\n",
      "\n",
      "مرحباً، معك عاطف. هيا لنتحدث :)\n",
      "\n",
      " أنت:مرحبا\n",
      "أهلاً بك\n",
      " أنت:لازلت أشعر بالخوف\n",
      "afraid\n",
      "عاطف :  ما الذي كنت خائفا منه؟\n",
      " أنت:عندما ذهبت إلى الغابة رأيت ثعبان كبير\n",
      "afraid\n",
      "عاطف :  هل عضك؟ هل أنت بخير؟\n",
      " أنت:أعتقد أنني محظوظة لم يحدث ذلك . كنت أشعر أنني خائفة على الرغم بأني كنت بخير\n",
      "afraid\n",
      "عاطف :  أنا سعيد لأنك بخير. بعضها سام ويمكن أن يقتل.\n",
      " أنت:وأيضا أتذكر عندما رأيت فأر كبير داخل المطبخ\n",
      "afraid\n",
      "عاطف :  ماذا فعلتم به؟ هل حاولت قتله؟\n",
      " أنت:لا أتذكر ولكنني حاولت إغلاق الباب عليه . ولكن لم أتمكن من أتصل بالصيانة بسبب تأخر الوقت\n",
      "afraid\n",
      "عاطف :  هذا ما كنت سأفعله. هل تم الاعتناء به؟\n",
      " أنت:نعم، وبرغم من ذلك أنا فخور فقد أنجزت الأعمال في الفناء , ولكن شعرت بالقذارة\n",
      "proud\n",
      "عاطف :  أنا فقط أحب ساحة العمل مع الأطفال. يقومون بمعظم العمل ونستمتع في التراب.\n",
      " أنت:يشعرني العشب بالحكة ولكن بعد الاستحمام اشعر بالراحة \n",
      "proud\n",
      "عاطف :  أوه لا. الحمام هو الجانب الإيجابي لكل الأوساخ التي أعتقد. وجدت ذات مرة ثعبانًا يحفر حفرة لزرع زهرة. تركت ذلك اليوم.\n",
      " أنت:أنني أشعر بشيء من الرعب خصوصا في الليل\n",
      "afraid\n",
      "عاطف :  مثل الأحلام السيئة أم ماذا؟\n",
      " أنت:إنها أحداث حقيقية :(\n",
      "afraid\n",
      "عاطف :  أوه ، هذا سيء حقًا ، آمل أن يتم التعامل معه.\n",
      " أنت:ولكنني سعيد جداا. استطعت إنقاذ سيدة عمياء كانت ستقع على السلم الكهربائي\n",
      "proud\n",
      "عاطف :  هل هي بخير؟ أنا سعيد لأنك كنت بالقرب منك!\n",
      " أنت:كانت منزعجة وهي لديها الحق . أنا أشعر بالسعادة لأنني فعلت الشيء الصحيح\n",
      "proud\n",
      "عاطف :  هذا أمر رائع حقًا منك ، هل رأى أي شخص آخر ذلك يحدث؟\n",
      " أنت:أمي فقط. وأيضا لدي أخبار سارة. أمي الان في سن 50 واستطاعت الحصول على درجة الماجستير في علوم الحاسبات\n",
      "proud\n",
      "عاطف :  واو هذا مذهل. يجب أن تكون فخورا جدا بها. أعتقد أن البرمجة ، وما إلى ذلك ، تبدو صعبة للغاية.\n",
      " أنت:أجل. فأنا لم أتعلم البرمجة أبدا. في حين أمي أنجزت تعلمها بالرغم من انها لم تكن تدرك ان المتصفح يعمل بالشفرة\n",
      "proud\n",
      "عاطف :  قصة ملهمة للغاية. إنهم يجنون أموالاً جيدة أيضًا.\n",
      " أنت:إلى اللقاء\n",
      "مع السلامة :)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "FILE = 'data.pth'\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data['input_size']\n",
    "hidden_size = data['hidden_size']\n",
    "output_size = data['output_size']\n",
    "all_words = data['all_words']\n",
    "context = data['contexts']\n",
    "model_state = data['model_state']\n",
    "\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval() #Eval Mode\n",
    "\n",
    "chatbot_name = 'عاطف'\n",
    "print('(اكتب \"إغلاق\" لإنهاء المحادثة)\\n')\n",
    "print('مرحباً، معك عاطف. هيا لنتحدث :)\\n')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    sentence = input(' أنت:')\n",
    "\n",
    "    if (ignore_words(sentence) == 'إغلاق'):\n",
    "        break\n",
    "    \n",
    "    elif ((ignore_words(sentence) == 'أهلا') or (ignore_words(sentence) == 'مرحبا')):\n",
    "        print('أهلاً بك')\n",
    "            \n",
    "    \n",
    "    elif ((ignore_words(sentence) == 'إلى اللقاء') or (ignore_words(sentence) == 'مع السلامة')):\n",
    "        print('مع السلامة :)')\n",
    "        break\n",
    "        \n",
    "        \n",
    "    else:\n",
    "\n",
    "        original_sentence = sentence\n",
    "        sentence = preprocessing(sentence)\n",
    "        X = bag_of_words(sentence, all_words)\n",
    "        X = X.reshape(1, X.shape[0])\n",
    "        X = torch.from_numpy(X)\n",
    "        \n",
    "        \n",
    "        # Predicting the Context (Sentiment)\n",
    "        \n",
    "        output = model(X)\n",
    "        _ , predicted = torch.max(output, dim=1)\n",
    "        context = contexts [predicted.item()]\n",
    "\n",
    "        probs = torch.softmax(output, dim=1)     #applying the Softmax Function\n",
    "        prob = probs[0][predicted.item()]\n",
    "\n",
    "        if prob.item() > 0.75:\n",
    "\n",
    "            print(context)\n",
    "\n",
    "            available_utt = []\n",
    "\n",
    "            for index, row in df.iterrows(): #get the input texts from the Utterance related to the predicted Context\n",
    "                if (row['context'] == context):\n",
    "                      if (row['utterance_idx'] % 2 == 1):\n",
    "                            available_utt.append(row['utterance'])\n",
    "                            \n",
    "            \n",
    "            # Mesausring Similarity based on tf-idf and Cosine Similarity \n",
    "\n",
    "            available_utt.append(original_sentence) #appending user original_sentence before any preprocessing\n",
    "\n",
    "            tfidf_vectorizer = TfidfVectorizer(tokenizer=preprocessing)\n",
    "            tfidf = tfidf_vectorizer.fit_transform(available_utt)\n",
    "            similar_vector_values = cosine_similarity(tfidf[-1], tfidf)\n",
    "            similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "\n",
    "            matched_vector = similar_vector_values.flatten()\n",
    "            matched_vector.sort()\n",
    "            vector_matched = matched_vector[-2]\n",
    "\n",
    "            if vector_matched == 0:\n",
    "                print('عذراً، لم أفهم')\n",
    "\n",
    "            else:\n",
    "                for index, row in df.iterrows(): #returning the Utterance Response of the most similar Utterance Input \n",
    "                    if (row['utterance'] == available_utt[similar_sentence_number]):\n",
    "                        print (chatbot_name, ': ', df['utterance'][index+1])\n",
    "                      \n",
    "\n",
    "        else:\n",
    "            print('عذراً، لم أفهم')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
